{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple Quality Prediction: An End-to-End Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Project Introduction\n",
    "\n",
    "This notebook walks through the process of building a machine learning model to predict the quality of apples (`good` or `bad`) based on a set of physical and chemical features.\n",
    "\n",
    "The project covers the following key stages:\n",
    "1. **Data Loading and Cleaning:** Importing the dataset and handling missing or inconsistent data.\n",
    "2. **Exploratory Data Analysis (EDA):** Visualizing the data to understand feature distributions and relationships.\n",
    "3. **Data Preprocessing:** Preparing the data for machine learning models.\n",
    "4. **Model Building and Evaluation:** Training several classification models and comparing their performance to select the best one.\n",
    "5. **Feature Importance Analysis:** Identifying which characteristics are most influential in determining apple quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Apple_Quality_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data types and look for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The dataset has 4000 entries. There seems to be a single missing value in the `Acidity` column. We will drop any rows with missing data to ensure a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that missing values have been handled\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'A_id' column is just an identifier and provides no predictive value, so we drop it.\n",
    "df.drop('A_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for and remove any duplicate rows\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Number of rows after dropping duplicates: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a statistical summary of the numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the 'Quality' column\n",
    "quality_counts = df['Quality'].value_counts()\n",
    "print(quality_counts)\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.countplot(x='Quality', data=df, palette=['#FF6347', '#32CD32'])\n",
    "plt.title('Distribution of Apple Quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The dataset is perfectly balanced, which is ideal for training a classification model as it avoids a natural bias towards one class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Feature Distributions (Univariate Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for all numerical features\n",
    "numerical_features = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness', 'Acidity']\n",
    "df[numerical_features].hist(bins=30, figsize=(15, 10), layout=(3, 3))\n",
    "plt.suptitle(\"Histograms of Numerical Features\")\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature Relationships (Bivariate Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the 'Quality' for correlation analysis ('good': 1, 'bad': 0)\n",
    "df['Quality_encoded_for_corr'] = df['Quality'].apply(lambda x: 1 if x == 'good' else 0)\n",
    "\n",
    "# Create a correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = df[numerical_features + ['Quality_encoded_for_corr']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap of All Features')\n",
    "\n",
    "# Save the figure to be used in the README\n",
    "plt.savefig('images/correlation_heatmap.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Drop the temporary encoded column\n",
    "df.drop('Quality_encoded_for_corr', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Insights:**\n",
    "- **Sweetness, Crunchiness, and Juiciness** show a moderate positive correlation with Quality.\n",
    "- **Acidity** shows a notable negative correlation, meaning higher acidity is linked to lower quality.\n",
    "- `Size` and `Weight` are highly correlated with each other, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots to see feature distributions per quality category\n",
    "for feature in numerical_features:\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.boxplot(x='Quality', y=feature, data=df, palette=['#FF6347', '#32CD32'])\n",
    "    plt.title(f'{feature} Distribution by Apple Quality')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Modeling\n",
    "\n",
    "Now, we will prepare the data and train several classification models to predict apple quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target variable 'Quality' into numerical format\n",
    "# 'good' will be 1, 'bad' will be 0\n",
    "le = LabelEncoder()\n",
    "df['Quality_encoded'] = le.fit_transform(df['Quality'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[numerical_features]\n",
    "y = df['Quality_encoded']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets\n",
    "# stratify=y ensures that the proportion of 'good' and 'bad' apples is the same in both train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training and Evaluating Models\n",
    "\n",
    "We will train four different models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Support Vector Machine\": SVC(random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Loop through models, train, and evaluate\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[name] = accuracy\n",
    "    \n",
    "    print(f\"--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Bad', 'Good']))\n",
    "    print(\"-\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results dictionary\n",
    "results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy'])\n",
    "results_df = results_df.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** The Random Forest Classifier performs the best with an accuracy of approximately 90.5%. Let's examine it more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 In-Depth Look at the Best Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is Random Forest\n",
    "best_model = models[\"Random Forest\"]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Plot the confusion matrix for the best model\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted Bad', 'Predicted Good'], \n",
    "            yticklabels=['Actual Bad', 'Actual Good'])\n",
    "plt.title('Confusion Matrix for Random Forest Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Analysis\n",
    "importances = best_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "\n",
    "# Sort the features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('Feature Importance for Apple Quality Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance Insight:** The model indicates that **Acidity**, **Ripeness**, and **Sweetness** are the top three most important features for predicting apple quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "This project successfully built and evaluated several machine learning models to classify apple quality. \n",
    "\n",
    "**Key Findings:**\n",
    "- **Best Model:** The **Random Forest Classifier** was the top-performing model, achieving an accuracy of **~90.5%** on the test set.\n",
    "- **Important Features:** The analysis of feature importance revealed that `Acidity`, `Ripeness`, and `Sweetness` are the most significant predictors of an apple's quality.\n",
    "- **Actionable Insight:** The strong negative correlation of `Acidity` and positive correlation of `Sweetness` confirm that these are primary drivers of consumer-perceived quality, providing a clear focus for quality control.\n",
    "\n",
    "Overall, the project demonstrates a practical application of data science to solve a real-world classification problem, from initial data exploration to final model deployment and interpretation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}